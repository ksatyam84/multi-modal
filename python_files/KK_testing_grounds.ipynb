{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdata_setup\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mRAW_DATA\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m raw_data_handler \u001b[38;5;28;01mas\u001b[39;00m rdh\n\u001b[1;32m      7\u001b[0m NUM_EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      8\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import data_setup\n",
    "from .raw_data_handler as rdh\n",
    "\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_UNITS = 25\n",
    "LEARNING_RATE = 0.05\n",
    "\n",
    "torch.manual_seed(42)  # Set seed for reproducibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    train_dir = \"/Users/kkodweis/Github-Repos/EAS510-BasicsAI/multi-modal/datasets/SampleV0/Train\"\n",
    "    test_dir = \"/Users/kkodweis/Github-Repos/EAS510-BasicsAI/multi-modal/datasets/SampleV0/Test\"\n",
    "\n",
    "    device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"\\nUsing device: {device}\\n\")\n",
    "\n",
    "    data_transform = utils.perspectiveV0()\n",
    "\n",
    "    train_dataloader, test_dataloader, class_labels = data_setup.create_dataloaders(\n",
    "        train_dir=train_dir,\n",
    "        test_dir=test_dir,\n",
    "        transform=data_transform.data_transform,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    model = model_builder.TinyVGG(input_shape=3, hidden_units=HIDDEN_UNITS, output_shape=len(class_labels)).to(device)\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(params=model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    engine.train(\n",
    "        model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        test_dataloader=test_dataloader,\n",
    "        optimizer=optimizer,\n",
    "        loss_fn=loss_fn,\n",
    "        device=device,\n",
    "        epochs=NUM_EPOCHS\n",
    "    )\n",
    "\n",
    "    utils.save_model(model=model,target_dir=\"models\", model_name=\"tinyvgg_model_V3.pth\")\n",
    "\n",
    "    \n",
    "    loaded_modelV2 = model_builder.TinyVGG(input_shape=3, hidden_units=HIDDEN_UNITS, output_shape=len(class_labels)).to(device)\n",
    "    loaded_modelV2.load_state_dict(torch.load(\"models/tinyvgg_model_V3.pth\"))\n",
    "\n",
    "    print(f\"Loaded model:\\n{loaded_modelV2}\")\n",
    "    print(f\"Model on device:\\n{next(loaded_modelV2.parameters()).device}\")\n",
    "\n",
    "    # Evaluate loaded model\n",
    "    loaded_modelV2.eval()\n",
    "    with torch.inference_mode():\n",
    "        loaded_modelV2_preds = loaded_modelV2(test_dataloader)\n",
    "    print(loaded_modelV2_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdh.set_root_path(\"/Users/kkodweis/Github-Repos/EAS510-BasicsAI/multi-modal/datasets\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "input_dataframe = pd.read_csv('/Users/kkodweis/Github-Repos/EAS510-BasicsAI/multi-modal/RAW_DATA/mymoviedb_EAS510.csv')\n",
    "\n",
    "for genre in data_setup.get_genres(input_dataframe):\n",
    "    print(f\"{genre}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_NAME = \"SampleV1\"  # Name of the sample directory\n",
    "\n",
    "labels = [ 'War', 'Horror']  #\"Comedy\", \"Western\", \"Thriller\",\n",
    "\n",
    "print(input_dataframe.columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rdh.mk_sample(SAMPLE_NAME, input_dataframe, \"Genre\", \"Poster_Urls\", labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
